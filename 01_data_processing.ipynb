{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 01. Data Processing & Advanced Feature Engineering\n",
                "\n",
                "**Objective:** Transform raw SQLite data into a high-quality dataset for predicting football match outcomes.\n",
                "\n",
                "**Key Steps:**\n",
                "1.  **Data Loading & Cleaning:** Handle missing values and types.\n",
                "2.  **Core Feature Engineering:** Betting odds, Rolling Form.\n",
                "3.  **Advanced Feature Engineering:**\n",
                "    *   **Elo Ratings:** Dynamic strength assessment.\n",
                "    *   **Head-to-Head (H2H):** Historical performance against specific opponents.\n",
                "    *   **Top Scorer Indicator:** identifying star players impact.\n",
                "    *   **Playing Style Clustering:** K-Means on Team Attributes.\n",
                "4.  **Output:** Save to `data/afterprocessing/processed_matches.csv`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sqlite3\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.cluster import KMeans\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from datetime import datetime\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "import warnings\n",
                "warnings.filterwarnings('ignore')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Data Loading & Cleaning"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DB_PATH = \"../data/database.sqlite\"\n",
                "\n",
                "conn = sqlite3.connect(DB_PATH)\n",
                "df_matches = pd.read_sql(\"SELECT * FROM Match\", conn)\n",
                "df_teams = pd.read_sql(\"SELECT * FROM Team\", conn)\n",
                "df_player_atts = pd.read_sql(\"SELECT * FROM Player_Attributes\", conn)\n",
                "df_team_atts = pd.read_sql(\"SELECT * FROM Team_Attributes\", conn)\n",
                "conn.close()\n",
                "\n",
                "print(f\"Matches: {df_matches.shape}, Teams: {df_teams.shape}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Sort by Date\n",
                "df_matches['date'] = pd.to_datetime(df_matches['date'])\n",
                "df_matches = df_matches.sort_values('date').reset_index(drop=True)\n",
                "\n",
                "# Clean Goals\n",
                "df_matches = df_matches.dropna(subset=['home_team_goal', 'away_team_goal'])\n",
                "\n",
                "# Target: 2=Home Win, 1=Draw, 0=Away Win\n",
                "conditions = [\n",
                "    df_matches['home_team_goal'] > df_matches['away_team_goal'],\n",
                "    df_matches['home_team_goal'] == df_matches['away_team_goal'],\n",
                "    df_matches['home_team_goal'] < df_matches['away_team_goal']\n",
                "]\n",
                "df_matches['target'] = np.select(conditions, [2, 1, 0], default=-1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Advanced Feature Engineering"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 Elo Rating & Head-to-Head (H2H)\n",
                "We calculate Elo dynamic ratings AND track history between specific pairs of teams (H2H)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def calculate_elo_prob(rating1, rating2):\n",
                "    return 1.0 / (1 + 10 ** ((rating2 - rating1) / 400.0))\n",
                "\n",
                "def update_elo(rating_home, rating_away, goal_diff, result, k=20, home_field_adv=100):\n",
                "    rating_home_adj = rating_home + home_field_adv\n",
                "    prob_home = calculate_elo_prob(rating_home_adj, rating_away)\n",
                "    \n",
                "    if goal_diff <= 1: G = 1\n",
                "    elif goal_diff == 2: G = 1.5\n",
                "    else: G = (11 + goal_diff) / 8.0\n",
                "        \n",
                "    new_rating_home = rating_home + k * G * (result - prob_home)\n",
                "    new_rating_away = rating_away + k * G * ((1 - result) - (1 - prob_home))\n",
                "    return new_rating_home, new_rating_away\n",
                "\n",
                "# Init State\n",
                "team_elos = {team_id: 1500 for team_id in df_teams['team_api_id'].unique()}\n",
                "h2h_data = {} # Key: tuple(sorted(id1, id2)), Value: {id1_wins: 0, id2_wins: 0, draws: 0}\n",
                "\n",
                "k_factor = 20\n",
                "\n",
                "# Feature Columns to build\n",
                "home_elo_col, away_elo_col, elo_probs_home = [], [], []\n",
                "h2h_home_wins_last3, h2h_away_wins_last3, h2h_draws_last3 = [], [], []\n",
                "\n",
                "for idx, row in df_matches.iterrows():\n",
                "    h_id, a_id = row['home_team_api_id'], row['away_team_api_id']\n",
                "    \n",
                "    # --- 1. ELO ---\n",
                "    h_elo = team_elos.get(h_id, 1500)\n",
                "    a_elo = team_elos.get(a_id, 1500)\n",
                "    \n",
                "    home_elo_col.append(h_elo)\n",
                "    away_elo_col.append(a_elo)\n",
                "    elo_probs_home.append(calculate_elo_prob(h_elo + 100, a_elo))\n",
                "    \n",
                "    # --- 2. H2H (Before updating with current result) ---\n",
                "    # Get history\n",
                "    pair_key = tuple(sorted((h_id, a_id)))\n",
                "    history = h2h_data.get(pair_key, [])\n",
                "    # History is list of results from perspective of team with smaller ID: \n",
                "    # e.g. [(match1_winner_id), (match2_winner_id), ...]\n",
                "    \n",
                "    # We want last 3 matches only\n",
                "    recent_history = history[-3:]\n",
                "    \n",
                "    w_home, w_away, w_draw = 0, 0, 0\n",
                "    for winner in recent_history:\n",
                "        if winner == h_id: w_home += 1\n",
                "        elif winner == a_id: w_away += 1\n",
                "        else: w_draw += 1\n",
                "            \n",
                "    h2h_home_wins_last3.append(w_home)\n",
                "    h2h_away_wins_last3.append(w_away)\n",
                "    h2h_draws_last3.append(w_draw)\n",
                "    \n",
                "    # --- UPDATE POST MATCH ---\n",
                "    h_goals, a_goals = row['home_team_goal'], row['away_team_goal']\n",
                "    goal_diff = abs(h_goals - a_goals)\n",
                "    \n",
                "    # Result for Elo\n",
                "    if h_goals > a_goals: res_elo = 1.0; res_h2h = h_id\n",
                "    elif h_goals == a_goals: res_elo = 0.5; res_h2h = 'draw'\n",
                "    else: res_elo = 0.0; res_h2h = a_id\n",
                "        \n",
                "    # Update Elo\n",
                "    new_h, new_a = update_elo(h_elo, a_elo, goal_diff, res_elo, k=k_factor)\n",
                "    team_elos[h_id] = new_h\n",
                "    team_elos[a_id] = new_a\n",
                "    \n",
                "    # Update H2H\n",
                "    if pair_key not in h2h_data: h2h_data[pair_key] = []\n",
                "    h2h_data[pair_key].append(res_h2h)\n",
                "\n",
                "df_matches['home_elo'] = home_elo_col\n",
                "df_matches['away_elo'] = away_elo_col\n",
                "df_matches['elo_diff'] = df_matches['home_elo'] - df_matches['away_elo']\n",
                "df_matches['elo_prob_home'] = elo_probs_home\n",
                "\n",
                "df_matches['h2h_home_wins'] = h2h_home_wins_last3\n",
                "df_matches['h2h_away_wins'] = h2h_away_wins_last3\n",
                "df_matches['h2h_draws'] = h2h_draws_last3"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 Top Scorer Indicator"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_player_atts['date'] = pd.to_datetime(df_player_atts['date'])\n",
                "df_player_atts['year'] = df_player_atts['date'].dt.year\n",
                "# Approx Top Player > 82 overall\n",
                "top_players_per_year = df_player_atts[df_player_atts['overall_rating'] >= 82].groupby('year')['player_api_id'].unique().to_dict()\n",
                "\n",
                "def check_top_player(row, side):\n",
                "    year = row['date'].year\n",
                "    # Check year and year-1\n",
                "    top_list = set(top_players_per_year.get(year, [])) | set(top_players_per_year.get(year-1, []))\n",
                "    count = 0\n",
                "    for i in range(1, 12):\n",
                "        pid = row[f'{side}_player_{i}']\n",
                "        if pd.notna(pid) and pid in top_list:\n",
                "            count += 1\n",
                "    return count\n",
                "\n",
                "df_matches['home_star_players'] = df_matches.apply(lambda x: check_top_player(x, 'home'), axis=1)\n",
                "df_matches['away_star_players'] = df_matches.apply(lambda x: check_top_player(x, 'away'), axis=1)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 Playing Style Clustering"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Preprocess Team Attributes (Forward Fill to prevent data loss)\n",
                "df_team_atts['date'] = pd.to_datetime(df_team_atts['date'])\n",
                "style_cols = ['buildUpPlaySpeed', 'buildUpPlayPassing', 'chanceCreationPassing', \n",
                "              'chanceCreationCrossing', 'chanceCreationShooting', \n",
                "              'defencePressure', 'defenceAggression', 'defenceTeamWidth']\n",
                "\n",
                "# Sort and Forward Fill per team\n",
                "df_team_atts.sort_values(['team_api_id', 'date'], inplace=True)\n",
                "df_team_atts[style_cols] = df_team_atts.groupby('team_api_id')[style_cols].ffill()\n",
                "\n",
                "df_team_atts_clean = df_team_atts.dropna(subset=style_cols).copy()\n",
                "\n",
                "if not df_team_atts_clean.empty:\n",
                "    scaler = StandardScaler()\n",
                "    X_style = scaler.fit_transform(df_team_atts_clean[style_cols])\n",
                "    kmeans = KMeans(n_clusters=3, random_state=42)\n",
                "    df_team_atts_clean['style_cluster'] = kmeans.fit_predict(X_style)\n",
                "    \n",
                "    df_team_atts_clean['date'] = pd.to_datetime(df_team_atts_clean['date'])\n",
                "    df_team_atts_clean.sort_values('date', inplace=True)\n",
                "    df_matches = df_matches.sort_values('date')\n",
                "    \n",
                "    for side in ['home', 'away']:\n",
                "        atts = df_team_atts_clean[['team_api_id', 'date', 'style_cluster']].copy()\n",
                "        atts.columns = [f'{side}_team_api_id', 'date', f'{side}_style']\n",
                "        df_matches = pd.merge_asof(df_matches, atts, on='date', by=f'{side}_team_api_id', direction='backward')\n",
                "    \n",
                "    df_matches[['home_style', 'away_style']] = df_matches[['home_style', 'away_style']].fillna(-1)\n",
                "else:\n",
                "    df_matches['home_style'] = -1\n",
                "    df_matches['away_style'] = -1"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 Form, Odds & Feature Divergence\n",
                "Calculating Betting Odds Implied Probabilities and Rolling Form (Points, GP, GF, GA)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 4. ROLLING FORM & STATS (Detailed) ---\n",
                "# Create a long-format database of team performances to calculate rolling stats correctly\n",
                "def build_team_stats(matches):\n",
                "    # Home stats\n",
                "    home = matches[['date', 'match_api_id', 'home_team_api_id', 'home_team_goal', 'away_team_goal', 'target']].copy()\n",
                "    home.columns = ['date', 'match_api_id', 'team_id', 'goals_for', 'goals_against', 'target']\n",
                "    home['is_home'] = 1\n",
                "    home['points'] = np.where(home['target'] == 2, 3, np.where(home['target'] == 1, 1, 0))\n",
                "    home['win'] = (home['target'] == 2).astype(int)\n",
                "    home['draw'] = (home['target'] == 1).astype(int)\n",
                "    \n",
                "    # Away stats\n",
                "    away = matches[['date', 'match_api_id', 'away_team_api_id', 'away_team_goal', 'home_team_goal', 'target']].copy()\n",
                "    away.columns = ['date', 'match_api_id', 'team_id', 'goals_for', 'goals_against', 'target']\n",
                "    away['is_home'] = 0\n",
                "    away['points'] = np.where(away['target'] == 0, 3, np.where(away['target'] == 1, 1, 0))\n",
                "    away['win'] = (away['target'] == 0).astype(int)\n",
                "    away['draw'] = (away['target'] == 1).astype(int)\n",
                "    \n",
                "    # Combine and sort\n",
                "    team_stats = pd.concat([home, away], ignore_index=True).sort_values(['team_id', 'date'])\n",
                "    return team_stats\n",
                "\n",
                "team_stats = build_team_stats(df_matches)\n",
                "\n",
                "# Calculate Rolling Stats\n",
                "windows = [5, 10]\n",
                "cols_to_roll = ['points', 'goals_for', 'goals_against', 'win', 'draw']\n",
                "\n",
                "# Group by team\n",
                "g = team_stats.groupby('team_id')\n",
                "\n",
                "for w in windows:\n",
                "    for col in cols_to_roll:\n",
                "        # Shift 1 to exclude current match from average\n",
                "        team_stats[f'last{w}_{col}'] = g[col].transform(lambda x: x.shift(1).rolling(w, min_periods=1).mean())\n",
                "\n",
                "# Fill NaNs (for first matches)\n",
                "roll_cols = [c for c in team_stats.columns if c.startswith('last')]\n",
                "team_stats[roll_cols] = team_stats[roll_cols].fillna(team_stats[roll_cols].mean()) # Simple mean fill for early games\n",
                "\n",
                "# Merge back to matches\n",
                "# We need to map team_stats back to home and away teams in df_matches\n",
                "home_stats = team_stats[team_stats['is_home'] == 1][['match_api_id'] + roll_cols].copy()\n",
                "home_stats.columns = ['match_api_id'] + [f'home_{c}' for c in roll_cols]\n",
                "\n",
                "away_stats = team_stats[team_stats['is_home'] == 0][['match_api_id'] + roll_cols].copy()\n",
                "away_stats.columns = ['match_api_id'] + [f'away_{c}' for c in roll_cols]\n",
                "\n",
                "df_matches = df_matches.merge(home_stats, on='match_api_id', how='left')\n",
                "df_matches = df_matches.merge(away_stats, on='match_api_id', how='left')\n",
                "\n",
                "# Calculate Differences (Home - Away)\n",
                "for col in roll_cols:\n",
                "    df_matches[f'diff_{col}'] = df_matches[f'home_{col}'] - df_matches[f'away_{col}']\n",
                "\n",
                "# Odds Implied Probabilities\n",
                "if 'B365H' in df_matches.columns:\n",
                "    df_matches['B365_prob_H'] = 1 / df_matches['B365H']\n",
                "    df_matches['B365_prob_D'] = 1 / df_matches['B365D']\n",
                "    df_matches['B365_prob_A'] = 1 / df_matches['B365A']\n",
                "    \n",
                "    # Divergence: Elo Probability vs Market Probability\n",
                "    df_matches['prob_diff_home'] = df_matches['elo_prob_home'] - df_matches['B365_prob_H']"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Save"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "os.makedirs('../data/afterprocessing', exist_ok=True)\n",
                "\n",
                "final_cols = [\n",
                "    'id', 'match_api_id', 'date', 'season', 'league_id', \n",
                "    'home_team_api_id', 'away_team_api_id', 'home_team_goal', 'away_team_goal', 'target',\n",
                "    'home_elo', 'away_elo', 'elo_diff', 'elo_prob_home',\n",
                "    'h2h_home_wins', 'h2h_away_wins', 'h2h_draws',\n",
                "    'home_star_players', 'away_star_players',\n",
                "    'home_style', 'away_style',\n",
                "    'B365H', 'B365D', 'B365A', 'B365_prob_H', 'B365_prob_D', 'B365_prob_A',\n",
                "    'prob_diff_home'\n",
                "]\n",
                "# Add dynamic rolling columns\n",
                "roll_feats = [c for c in df_matches.columns if c.startswith('home_last') or c.startswith('away_last') or c.startswith('diff_last')]\n",
                "final_cols.extend(roll_feats)\n",
                "\n",
                "cols_to_save = [c for c in final_cols if c in df_matches.columns]\n",
                "\n",
                "df_matches[cols_to_save].to_csv('../data/afterprocessing/processed_matches.csv', index=False)\n",
                "print(\"Data saved to data/afterprocessing/processed_matches.csv\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
